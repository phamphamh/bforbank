// Import du module de configuration
import { config, loadEnvVariables } from './config.js';

// Variables globales
let API_KEY = ''; // La cl√© sera charg√©e depuis .env
let mediaRecorder;
let audioChunks = [];
let isRecording = false;
let audioBlob;

// Fonction d'initialisation
document.addEventListener('DOMContentLoaded', async () => {
  // Chargement des variables d'environnement
  await loadEnvVariables();
  API_KEY = config.API_KEY;

  if (!API_KEY) {
    console.error('Cl√© API non trouv√©e. Assurez-vous que le fichier .env contient OPENAI_API_KEY.');
  }

  // Cr√©ation des √©l√©ments d'interface
  const app = document.createElement('div');
  app.innerHTML = `
    <div class="container">
      <h1>Assistant Bancaire - Reconnaissance Vocale</h1>
      <div class="controls">
        <button id="recordButton" class="record-btn">Commencer l'enregistrement</button>
        <div id="status" class="status">Pr√™t</div>
      </div>
      <div class="result-container">
        <h2>Transcription</h2>
        <div id="transcription" class="transcription"></div>
      </div>
      <div class="result-container">
        <h2>Analyse</h2>
        <div id="analysis" class="analysis"></div>
      </div>
    </div>
  `;
  document.body.appendChild(app);

  // Ajout du style CSS
  const style = document.createElement('style');
  style.textContent = `
    .container {
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      font-family: Arial, sans-serif;
    }
    .controls {
      display: flex;
      align-items: center;
      margin-bottom: 20px;
    }
    .record-btn {
      background-color: #007bff;
      color: white;
      border: none;
      padding: 10px 20px;
      border-radius: 5px;
      cursor: pointer;
      font-size: 16px;
      transition: background-color 0.3s;
    }
    .record-btn.recording {
      background-color: #dc3545;
    }
    .status {
      margin-left: 20px;
      font-style: italic;
    }
    .result-container {
      background-color: #f8f9fa;
      border-radius: 5px;
      padding: 15px;
      margin-bottom: 20px;
    }
    .transcription, .analysis {
      min-height: 100px;
      border: 1px solid #ddd;
      border-radius: 5px;
      padding: 10px;
      background-color: white;
    }
    .analysis {
      white-space: pre-line;
    }
    .resolution-facile {
      background-color: #d4edda;
      border: 1px solid #c3e6cb;
      border-radius: 5px;
      padding: 10px 15px;
      margin-bottom: 10px;
    }
    .resolution-facile h3 {
      color: #155724;
      margin-top: 0;
    }
    .resolution-transfert {
      background-color: #fff3cd;
      border: 1px solid #ffeeba;
      border-radius: 5px;
      padding: 10px 15px;
      margin-bottom: 10px;
    }
    .resolution-transfert h3 {
      color: #856404;
      margin-top: 0;
    }
    .method-steps {
      background-color: #e2e3e5;
      border-radius: 5px;
      padding: 10px;
      margin: 10px 0;
    }
  `;
  document.head.appendChild(style);

  // Ajout des gestionnaires d'√©v√©nements
  const recordButton = document.getElementById('recordButton');
  const status = document.getElementById('status');

  recordButton.addEventListener('click', async () => {
    if (!isRecording) {
      startRecording();
      recordButton.textContent = 'Arr√™ter l\'enregistrement';
      recordButton.classList.add('recording');
      status.textContent = 'Enregistrement en cours...';
    } else {
      stopRecording();
      recordButton.textContent = 'Commencer l\'enregistrement';
      recordButton.classList.remove('recording');
      status.textContent = 'Traitement en cours...';
    }
  });
});

// Fonction pour d√©marrer l'enregistrement
async function startRecording() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream);
    isRecording = true;
    audioChunks = [];

    mediaRecorder.addEventListener('dataavailable', event => {
      audioChunks.push(event.data);
    });

    mediaRecorder.addEventListener('stop', processAudio);
    mediaRecorder.start();
  } catch (error) {
    console.error('Erreur lors de l\'acc√®s au microphone:', error);
    document.getElementById('status').textContent = 'Erreur: impossible d\'acc√©der au microphone';
  }
}

// Fonction pour arr√™ter l'enregistrement
function stopRecording() {
  if (mediaRecorder && isRecording) {
    mediaRecorder.stop();
    isRecording = false;
    mediaRecorder.stream.getTracks().forEach(track => track.stop());
  }
}

// Fonction pour traiter l'audio enregistr√©
async function processAudio() {
  audioBlob = new Blob(audioChunks, { type: 'audio/webm' });

  // Afficher la dur√©e de l'enregistrement
  const audioDuration = await getAudioDuration(audioBlob);
  console.log(`Dur√©e d'enregistrement: ${audioDuration.toFixed(2)} secondes`);

  // V√©rifier si l'enregistrement est trop court
  if (audioDuration < 0.5) {
    document.getElementById('status').textContent = 'Enregistrement trop court, veuillez r√©essayer';
    return;
  }

  document.getElementById('status').textContent = 'Transcription en cours...';

  // Transcrire l'audio
  try {
    const transcription = await transcribeAudio(audioBlob);
    document.getElementById('transcription').textContent = transcription;
    document.getElementById('status').textContent = 'Analyse en cours...';

    // Analyser la transcription
    const analysis = await analyzeTranscription(transcription);

    // Formatage visuel de l'analyse
    let formattedAnalysis = analysis;

    // Mise en forme des sections cl√©s
    const sections = {
      'BESOIN:': '<strong>BESOIN:</strong>',
      'D√âLAI:': '<strong>D√âLAI:</strong>',
      'EXPERTISE:': '<strong>EXPERTISE:</strong>',
      'PRIORIT√â:': '<strong>PRIORIT√â:</strong>',
      'R√âSOLUTION:': '<strong>R√âSOLUTION:</strong>',
      'M√âTHODE DE R√âSOLUTION:': '<strong>M√âTHODE DE R√âSOLUTION:</strong>',
      'BRANCHE COMP√âTENTE:': '<strong>BRANCHE COMP√âTENTE:</strong>',
      'JUSTIFICATION:': '<strong>JUSTIFICATION:</strong>'
    };

    Object.keys(sections).forEach(key => {
      formattedAnalysis = formattedAnalysis.replace(key, sections[key]);
    });

    // D√©tection de r√©solution facile ou transfert
    if (analysis.includes('R√âSOLUTION: Oui') || analysis.includes('R√âSOLUTION: oui')) {
      // Extraction de la m√©thode de r√©solution
      const methodMatch = analysis.match(/M√âTHODE DE R√âSOLUTION:([\s\S]*?)(?=BRANCHE COMP√âTENTE:|JUSTIFICATION:|$)/);
      let methodContent = '';

      if (methodMatch && methodMatch[1]) {
        methodContent = `<div class="method-steps">
          <h4>üìã √âtapes √† suivre:</h4>
          ${methodMatch[1].trim()}
        </div>`;
      }

      formattedAnalysis = `<div class="resolution-facile">
        <h3>‚úÖ R√âSOLUTION FACILE</h3>
        ${formattedAnalysis.replace(/M√âTHODE DE R√âSOLUTION:([\s\S]*?)(?=BRANCHE COMP√âTENTE:|JUSTIFICATION:|$)/, `<strong>M√âTHODE DE R√âSOLUTION:</strong>${methodContent}`)}
      </div>`;
    } else if (analysis.includes('BRANCHE COMP√âTENTE:')) {
      // Extraction de la branche comp√©tente
      const brancheMatch = analysis.match(/BRANCHE COMP√âTENTE:([^\n]+)/);
      const branche = brancheMatch ? brancheMatch[1].trim() : 'Ind√©termin√©e';

      formattedAnalysis = `<div class="resolution-transfert">
        <h3>üîÑ TRANSFERT REQUIS: ${branche}</h3>
        ${formattedAnalysis}
      </div>`;
    }

    document.getElementById('analysis').innerHTML = formattedAnalysis;
    document.getElementById('status').textContent = 'Pr√™t';
  } catch (error) {
    console.error('Erreur lors du traitement audio:', error);
    document.getElementById('status').textContent = 'Erreur de traitement, veuillez r√©essayer';
  }
}

// Fonction pour obtenir la dur√©e de l'audio
function getAudioDuration(blob) {
  return new Promise((resolve) => {
    const audio = new Audio();
    audio.src = URL.createObjectURL(blob);
    audio.onloadedmetadata = () => {
      resolve(audio.duration);
    };
  });
}

// Fonction pour envoyer l'audio √† l'API OpenAI pour transcription
async function transcribeAudio(audioBlob) {
  const formData = new FormData();
  formData.append('file', audioBlob, 'recording.webm');
  formData.append('model', 'whisper-1');
  formData.append('language', 'fr');

  try {
    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${API_KEY}`
      },
      body: formData
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Erreur OpenAI: ${errorData.error?.message || 'Erreur inconnue'}`);
    }

    const data = await response.json();
    return data.text;
  } catch (error) {
    console.error('Erreur de transcription:', error);
    throw error;
  }
}

// Fonction pour analyser la transcription avec l'API OpenAI
async function analyzeTranscription(text) {
  if (!text || text.trim() === '') {
    return 'Aucun texte √† analyser.';
  }

  const prompt = `
  Vous √™tes un assistant sp√©cialis√© pour les conseillers bancaires. Analysez la demande du client suivante et fournissez:

  1. BESOIN: Une synth√®se claire du besoin du client en 1-2 phrases
  2. D√âLAI: Une estimation du d√©lai n√©cessaire pour traiter cette demande (imm√©diat, quelques jours, semaines)
  3. EXPERTISE: Le domaine d'expertise bancaire concern√© (cr√©dit, √©pargne, assurance, placement, op√©rations courantes, etc.)
  4. PRIORIT√â: Niveau d'urgence (faible, moyenne, √©lev√©e)
  5. R√âSOLUTION: √âvaluez si le probl√®me peut √™tre r√©solu facilement et directement par le conseiller (oui/non)
  6. M√âTHODE DE R√âSOLUTION: Si r√©solution facile, d√©crivez pr√©cis√©ment les √©tapes √† suivre en 2-3 points
  7. BRANCHE COMP√âTENTE: Si r√©solution complexe, indiquez la branche √† laquelle transf√©rer la demande parmi:
     - MO AV et Succession (assurance vie, d√©c√®s, h√©ritage)
     - MO Administratif et reglementaire (conformit√©, documents l√©gaux)
     - MO d√©biteur et Cr√©dit (pr√™ts, d√©couverts)
     - MO Entr√©e en Relation (nouveaux clients, ouverture de compte)
     - MO Flux Sepa & Internationaux (virements internationaux)
     - MO fraude (suspicion de fraude, contestations)
     - MO Moyen de Paiments (cartes, ch√®ques)
     - MO R√©conciliations Bancaires (anomalies sur comptes)
     - MO Titres (investissements, bourse)
     - MO trasitions (changements de produits/services)
     - MO Vie du compte (op√©rations courantes)
  8. JUSTIFICATION: Expliquez en 1-2 phrases pourquoi ce cas devrait √™tre trait√© par cette branche sp√©cifique

  Demande du client: "${text}"`;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: 'Vous √™tes un assistant sp√©cialis√© dans l\'analyse des demandes bancaires. R√©pondez de mani√®re structur√©e et concise.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.7
      })
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Erreur OpenAI: ${errorData.error?.message || 'Erreur inconnue'}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  } catch (error) {
    console.error('Erreur d\'analyse:', error);
    throw error;
  }
}